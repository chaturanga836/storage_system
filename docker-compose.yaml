networks:
    iceberg-net:
        driver: bridge
    kafka-net: # Separate network for Kafka components
        driver: bridge

volumes:
    minio-data:
    kafka-data-1: # Volume for Kafka broker 1 data
    kafka-data-2: # Volume for Kafka broker 2 data (for a simple multi-broker setup)
    kafka-data-3: # Volume for Kafka broker 3 data
    trino-data: # For Trino's configuration files
    nessie-postgres-data: # Volume for Nessie's PostgreSQL data

services:
    nessie:
        image: ghcr.io/projectnessie/nessie:latest
        container_name: nessie
        ports:
            - "4000:19120"

        environment:
        - QUARKUS_HTTP_PORT=19120
        - QUARKUS_PROFILE=dev
        - nessie.version.store.type=JDBC2
        - nessie.version.store.persist.jdbc2.datasource.jdbc-url=jdbc:postgresql://nessie-postgres:5432/nessie_db
        - nessie.version.store.persist.jdbc2.datasource.username=nessie
        - nessie.version.store.persist.jdbc2.datasource.password=nessie123
        - nessie.version.store.persist.jdbc2.datasource.adapter=postgres
        depends_on:
            postgres:
                condition: service_healthy
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:19120/api/v2/config"]
            interval: 10s
            timeout: 5s
            retries: 5
        networks:
            - iceberg-net

    minio:
        image: minio/minio
        container_name: minio
        command: server /data --console-address ":9001"
        ports:
            - "4003:9000"
            - "4004:9001"
        environment:
            MINIO_ROOT_USER: minioadmin
            MINIO_ROOT_PASSWORD: minioadmin
        volumes:
            - minio-data:/data
        networks:
            - iceberg-net
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
            interval: 5s
            timeout: 5s
            retries: 12

    # --- Trino (Query Engine) ---
    trino:
        image: trinodb/trino:476
        container_name: trino
        ports:
            - "4001:8080" # Trino UI and JDBC/ODBC port
        volumes:
            - /home/ubuntu/storage_system/trino/config:/etc/trino
            - trino-data:/var/lib/trino/data # For Trino's internal data (e.g., query history, plugins)
        environment:
            # Optional: To enable dynamic catalog management via SQL
            - CATALOG_MANAGEMENT=dynamic
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:8080/v1/info"]
            interval: 10s
            timeout: 5s
            retries: 5
        networks:
            - iceberg-net # Connects to Nessie and MinIO
            - kafka-net # Connects to Kafka for Kafka connector
        depends_on:
            nessie:
                condition: service_healthy
            minio:
                condition: service_healthy

    # --- Kafka Cluster (KRaft Mode) ---
    # We'll set up a 3-node KRaft cluster for robustness
    # You'll need to generate a CLUSTER_ID once
    # Run: `docker run --rm confluentinc/cp-kafka:latest kafka-storage random-uuid`
    # And replace 'your_generated_cluster_id' below
    kafka1:
        image: confluentinc/cp-kafka:7.6.0 # Confluent's image supports KRaft well
        container_name: kafka1
        hostname: kafka1
        ports:
            - "4005:9092" # External listener
        environment:
            KAFKA_NODE_ID: 1
            KAFKA_PROCESS_ROLES: "broker,controller"
            KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka1:9093,2@kafka2:9093,3@kafka3:9093"
            KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
            KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka1:9092"
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
            KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
            KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
            CLUSTER_ID: "9S6Pyu-5SJyPfCJ-cBdgQw"
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
        volumes:
            - kafka-data-1:/var/lib/kafka/data
        networks:
            - kafka-net

    kafka2:
        image: confluentinc/cp-kafka:7.6.0
        container_name: kafka2
        hostname: kafka2
        ports:
            - "4006:9093" # External listener
        environment:
            KAFKA_NODE_ID: 2
            KAFKA_PROCESS_ROLES: "broker,controller"
            KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka1:9093,2@kafka2:9093,3@kafka3:9093"
            KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
            KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka2:9092"
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
            KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
            KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
            CLUSTER_ID: "9S6Pyu-5SJyPfCJ-cBdgQw"
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
        volumes:
            - kafka-data-2:/var/lib/kafka/data
        networks:
            - kafka-net
        depends_on:
            - kafka1 # Ensure kafka1 starts first for quorum formation

    kafka3:
        image: confluentinc/cp-kafka:7.6.0
        container_name: kafka3
        hostname: kafka3
        ports:
            - "4007:9094" # External listener
        environment:
            KAFKA_NODE_ID: 3
            KAFKA_PROCESS_ROLES: "broker,controller"
            KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka1:9093,2@kafka2:9093,3@kafka3:9093"
            KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
            KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka3:9092"
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
            KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
            KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
            CLUSTER_ID: "9S6Pyu-5SJyPfCJ-cBdgQw"
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
            KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
            KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
        volumes:
            - kafka-data-3:/var/lib/kafka/data
        networks:
            - kafka-net
        depends_on:
            - kafka1
            - kafka2

    kafka-ui:
        image: provectuslabs/kafka-ui:latest
        container_name: kafka-ui
        ports:
            - "4008:8080" # Map to 8081 to avoid conflict with Trino's 8080
        environment:
            KAFKA_CLUSTERS_0_NAME: local-kraft-cluster
            KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:9092,kafka2:9092,kafka3:9092
            KAFKA_UI_BASE_PATH: /kafka-ui
        networks:
            - kafka-net
        depends_on:
            - kafka1
            - kafka2
            - kafka3

    iceberg-rest-catalog:
        image: tabulario/iceberg-rest
        container_name: iceberg-rest-catalog
        ports:
            - "8181:8181"
        environment:
            - AWS_ACCESS_KEY_ID=minioadmin
            - AWS_SECRET_ACCESS_KEY=minioadmin
            - AWS_REGION=us-east-1
            - CATALOG_WAREHOUSE=s3://nessie-warehouse-bucket/
            - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
            - CATALOG_S3_ENDPOINT=http://minio:9000
            - CATALOG_S3_PATH_STYLE_ACCESS=true # âœ… Added to fix the DNS resolution error
            - CATALOG_NESSIE_URI=http://nessie:19120/api/v2
            - CATALOG_CATALOG_IMPL=org.apache.iceberg.rest.RESTCatalog
        depends_on:
            nessie:
                condition: service_healthy
            minio:
                condition: service_healthy
        networks:
            - iceberg-net

    postgres:
        image: postgres:14
        container_name: nessie-postgres
        environment:
            POSTGRES_USER: nessie
            POSTGRES_PASSWORD: nessie123
            POSTGRES_DB: nessie_db
        ports:
            - "5432:5432"
        volumes:
            - nessie-postgres-data:/var/lib/postgresql/data
        networks:
            - iceberg-net
        healthcheck:
            test: ["CMD-SHELL", "pg_isready -U nessie"]
            interval: 5s
            timeout: 5s
            retries: 5
